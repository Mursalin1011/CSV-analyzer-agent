# CSV Insights API Documentation\n\nThis document provides detailed information about the CSV Insights API endpoints, request/response formats, and usage examples.\n\n## Base URL\n\n```\nhttp://localhost:8000\n```\n\nWhen running on your local network, you can also access it via:\n```\nhttp://YOUR_LOCAL_IP:8000\n```\n\n## API Endpoints\n\n### 1. Health Check\n\n**GET** `/health`\n\nCheck if the API is running and healthy.\n\n#### Response\n```json\n{\n  \"status\": \"healthy\",\n  \"llm_provider\": \"gemini\"  // or \"ollama\"\n}\n```\n\n### 2. Upload File and Get Insights\n\n**POST** `/insights/file`\n\nUpload a CSV, Excel (XLSX/XLS), or JSON file to generate AI-powered insights.\n\n#### Request\n\n**Form Data:**\n- `file`: The file to analyze (CSV, XLSX, XLS, or JSON)\n\n#### Response\n\n```json\n{\n  \"insights\": \"string\",  // AI-generated insights in markdown format\n  \"cache_key\": \"string\"  // Unique identifier for caching\n}\n```\n\n#### Example Response\n\n```json\n{\n  \"insights\": \"### Dataset Analysis\\n\\n#### Key Patterns/Trends\\n- The dataset contains 1000 entries with 5 columns\\n- Age distribution is fairly uniform between 20-60 years\\n- Salary shows a positive correlation with experience\\n\\n#### Notable Correlations/Anomalies\\n- Strong positive correlation (0.78) between years_of_experience and salary\\n- Outliers detected in the salary column (3 entries above 2 standard deviations)\\n\\n#### Business Implications\\n- The data suggests a consistent compensation structure\\n- Consider investigating the salary outliers for potential discrepancies\\n\\n#### Analysis Recommendations\\n- Perform a deeper regression analysis on salary predictors\\n- Segment analysis by department for more granular insights\",\n  \"cache_key\": \"a1b2c3d4e5f67890\"\n}\n```\n\n### 3. Get Insights by Cache Key\n\n**GET** `/insights/{cache_key}`\n\nRetrieve previously generated insights using the cache key.\n\n#### Request\n\n**Path Parameters:**\n- `cache_key`: The unique identifier returned from file upload\n\n#### Response\n\n```json\n{\n  \"insights\": \"string\",  // AI-generated insights in markdown format\n  \"cache_key\": \"string\"  // The cache key used for retrieval\n}\n```\n\n#### Error Response\n\nIf the cache key is not found:\n```json\n{\n  \"detail\": \"Insights not found for this key\"\n}\n```\n\n## Supported File Formats\n\n- **CSV** (.csv)\n- **Excel** (.xlsx, .xls)\n- **JSON** (.json)\n\n## Usage Examples\n\n### cURL Examples\n\n#### Health Check\n```bash\ncurl -X GET \"http://localhost:8000/health\"\n```\n\n#### Upload File\n```bash\ncurl -X POST \"http://localhost:8000/insights/file\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F \"file=@sample_data.csv\"\n```\n\n#### Get Insights by Cache Key\n```bash\ncurl -X GET \"http://localhost:8000/insights/a1b2c3d4e5f67890\"\n```\n\n### Python Example\n\n```python\nimport requests\n\n# Upload file and get insights\nwith open('sample_data.csv', 'rb') as f:\n    files = {'file': f}\n    response = requests.post('http://localhost:8000/insights/file', files=files)\n    result = response.json()\n    print(\"Insights:\", result['insights'])\n    print(\"Cache Key:\", result['cache_key'])\n\n# Retrieve insights by cache key\ncache_key = result['cache_key']\nresponse = requests.get(f'http://localhost:8000/insights/{cache_key}')\ninsights = response.json()\nprint(\"Cached Insights:\", insights['insights'])\n```\n\n## Error Handling\n\nThe API returns standard HTTP status codes:\n\n- **200**: Success\n- **400**: Bad Request (e.g., unsupported file format)\n- **404**: Not Found (e.g., cache key not found)\n- **500**: Internal Server Error (e.g., processing error)\n\n## Caching\n\nResults are cached in a SQLite database to avoid reprocessing the same file. The cache key is generated based on a sample of the data, so identical files will return the same cache key and retrieve cached results.\n\n## LLM Providers\n\nThe API supports two LLM providers:\n\n1. **Google Gemini** (default) - Requires API key\n2. **Ollama** (local) - Requires Ollama running locally\n\nSwitch between providers using environment variables:\n```\nLLM_PROVIDER=gemini\nGOOGLE_API_KEY=your_api_key_here\n\n# Or for Ollama:\nLLM_PROVIDER=ollama\nOLLAMA_BASE_URL=http://localhost:11434\nOLLAMA_MODEL=qwen3:0.6b\n```\n\n## Accessing Swagger UI\n\nOnce the API is running, you can access the interactive Swagger documentation at:\n```\nhttp://localhost:8000/docs\n```\n\nThis provides an interactive interface to test all API endpoints directly from your browser.